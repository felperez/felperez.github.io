---
title: 'Large deviations'
date: 2019-07-15
permalink: /posts/2019/07/blog-post-13/
tags:
  - probability theory

  - measure theory

  - limit laws

  - large deviations

  - Cramer's theorem
---

In the previous entries we have studied the asymptotic behavior of the sums of iid random variables. The law of large numbers showed that almost surely, the averages converge to the mean, while the central limit theorem gave us a second order approximation, that is, it provided information of the size of the fluctuations around the expected value. In this entry, we discuss a third order result, namely, Cramer's theorem on large deviations. Intuitively, Cramer's theorem establishes asymptotic rates for the decay of the probability of observing very unlikely events.

Let $\\{X\_n \\}$ be a sequence of iid random variables with mean $\mu$, and suppose that the variables have finite log-moment generating function

$$
\varphi(\lambda) = \log \mathbb{E}e^{\lambda X_1} \lt \infty
$$

for all $\lambda\in\mathbb{R}$.

**Theorem (Cramer):** Let $S\_n = X\_1 + \dots + X\_n$ and $x > \mu$. Then

$$
\lim_{n\to\infty}\dfrac{1}{n} \log \mathbb{P}\{ S_n \geq nx\} = -\varphi^*(x),
$$

where $\varphi^\*$ is the Legendre transform of $\varphi$.

Recall that the Legendre transform of $\varphi$ is given by

$$
\varphi^*(x) = \sup_{\lambda\in\mathbb{R}} \{\lambda x -\varphi(\lambda) \}.
$$

We will prove the theorem in two parts: first the upper bound, which uses a standard Chernoff bound technique, then the lower bound, which uses a measure tilting argument.

**Proof:** (Upper bound). For $\lambda \geq 0$, we have by Markov's inequality

$$
\mathbb{P}\{ S_n \geq nx \} = \mathbb{P}\{ e^{\lambda S_n} \geq e^{\lambda nx} \} \leq e^{-\lambda nx} \mathbb{E}(e^{\lambda S_n}).
$$

This implies that

$$
\limsup_{n \to \infty} \dfrac{1}{n} \log \mathbb{P}\{\frac{1}{n} S_{n} \geq x\} \leq -\lambda  x + \limsup_{n \to \infty} \dfrac{1}{n} \log \mathbb{E}(e^{\lambda S_n}) = -\lambda n x  + \varphi(\lambda)
$$
