---
title: 'Statistical properties in hyperbolic dynamics, part 2'
date: 2019-06-04
permalink: /posts/2019/05/blog-post-6/
tags:
  - probability theory

  - measure theory

  - limit laws

  - dynamical systems

  - hyperbolic dynamics

  - transfer operator
---

This is the second post of a series of 4 posts based on the lectures at the [Houston Summer School on Dynamical Systems 2019](https://www.math.uh.edu/dynamics/school/school2019/) on Statistical properties in hyperbolic dynamics, given by Matthew Nicol, Andrew Török and William Ott. These notes are heavily edited with added comments, examples and explanations. Any mistake is of my responsibility. Some of the notation has been changed for consistency.

## Lecture 2

In this lecture we will explore in more depth the transfer operator method, as well as Gordin's martingale approximation method.

Recall the setting from the previous lecture: let $T\colon X\to X$ be a measure preserving transformation of the probability space $(X,\mu)$. For a regular enough observable $\phi\colon X \to\mathbb{R}$, we constructed the time series $X\_n = \phi\circ T^n$. We are interested in the limit laws of this time series. For this, we will write the observable as

$$
\phi = \psi + g - g\circ T
$$

for functions $\psi,g$, so that when we compute the Birkhoff sums, we obtaining

$$
\sum_{j=1}^n \phi\circ T^j = \sum_{j=1}^n \psi\circ T^j + g(x) - g\circ T^{n+1}(x).
$$

The idea is that the sum on the right hand side is a reverse martingale, and the two remaining terms are controllable.

## Probability recap

Let $(\Omega,\mathbb{P})$ be a probility space with sigma-algebra $\mathcal{B}$ and $\mathcal{F}\subset\mathcal{B}$ a sub sigma-algebra. If $Y$ is a random variable with finite expectation, define the *conditional expectation* of $Y$ with respect to $\mathcal{F}$, denoted by $\mathbb{E}(Y | \mathcal{F})$ to be the unique (up to zero measure sets) random variable $Z$ with the following properties:
1. $Z$ is $\mathcal{F}$-measurable
2. for every set $A\in\mathcal{F}$,

$$
\int_A Z d\mathbb{P} = \int_A Y d\mathbb{P}.
$$

The existence of $\mathbb{E}(Y \| \mathcal{F})$ can be proved using [Radon-Nikodym's theorem](https://en.wikipedia.org/wiki/Radon–Nikodym_theorem) We list now some easy to check properties of the conditional expectation:

**Properties:**
1. $\mathbb{E}(\cdot \| \mathcal{F})$ is a linear operator,
2. $\mathbb{E}(\cdot \| \mathcal{F})$ is a positive operator,
3. $\int\_{\Omega} \mathbb{E}(X\|\mathcal{F}) dP = \int\_{\Omega} X dP$ for every integrable random variable $X$,
4. if $\mathcal{F}_1\subset\mathcal{F}_2\subset\mathcal{B}$ then $\mathbb{E}(\mathbb{E}(X\| \mathcal{F_2})\|\mathcal{F}_1) = \mathbb{E}(X\|\mathcal{F}_1)$,
5. if $X\in\mathcal{F}$ and $\mathcal{B}(X),\mathbb{E}(XY)<\infty$, then $\mathbb{E}(XY\| \mathcal{F}) = X\mathbb{E}(Y\|\mathcal{F})$,
6. if $X$ is $\mathcal{F}$-measurable, then $\mathbb{E}(X\|\mathcal{F}) = X$.

We can now give a definition of a martingale. A sequence of sub sigma-algebras $(\mathcal{F}_n)$ is a *filtration* if $\mathcal{F}_n\subset\mathcal{F}\_{n+1}$ for all $n$. A stochastic process $(M_n)$ is a *martingale* with respect to the filtration $(\mathcal{F}_n)$ if
1. $\mathbb{E}(\|M_n\|) \lt \infty$,
2. $M_n$ is $\mathcal{F}_n$-measurable,
3. $\mathbb{E}(M_{n+1}\|\mathcal{F}_n) =  M_n$.

In this setting, we call $X_n = M\_{n+1} - M_n$ a *martingale difference*.

**Remark:** if $M_n = X_1 + \dots + X_n$ and we take the filtration $\mathcal{F}_n = \sigma(X_1,\dots,X_n)$, then $(M_n)$ is a martingale if and only if $\mathbb{E}(X\_{n+1}\| \mathcal{F}_n) = 0$.

## Transfer operator revisited

Recall the definition of the transfer operator $P$ as the dual of the Koopman operator:

$$
\int_X \phi\cdot\psi\circ T d\mu = \int_X P\phi \cdot \psi d\mu
$$

for observables $\phi\in L^1$ and $\psi\in L^\infty$. In this section we will discuss how we can express the action of the transfer and the Koopman operators in terms of conditional expectations. Let $\mathcal{F}_n = T^{-n}\mathcal{B}$, where $\mathcal{B}$ is the sigma-algebra of the underlying phase space $X$.

**Proposition:** for every $\phi\in L^1$ we have:
1. $\mathbb{E}(\phi \| T^{-1}\mathcal{B}) = UP\phi = (P\phi)\circ T$ and similarly $\mathbb{E}(\phi \| T^{-i}\mathcal{B}) = U^iP^i\phi$.
2. $PU\phi = \phi$ and $P^iU^i \phi = \phi$.

**Proof:** for the first part, we have to show that $UP\phi$ is $T^{-1}\mathcal{B}$-measurable and that

$$
\int_A UP\phi d\mu = \int_A \phi d\mu
$$

for every set $A\in T^{-1}\mathcal{B}$. Note that $(P\phi\circ T)^{-1}(B) = T^{-1}(P\phi)^{-1}(B)$ for every set $B\in\mathcal{B}$, thus the measurability condition holds. Using invariance and duality, we have

$$
\int_{T^{-1}A} UP\phi d\mu = \int_X (P\phi)\circ T 1_{T^{-1}A} d\mu = \int_X (P\phi)\circ T 1_A\circ Td\mu
$$

$$
\qquad = \int_X (P\phi) 1_A d\mu = \int_X \phi 1_A\circ T d\mu = \int_{T^{-1}A}\phi d\mu.
$$

This shows the first property.
